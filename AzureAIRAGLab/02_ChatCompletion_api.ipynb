{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This notebook helps you to understand and chat with Azure OpenAI API to explore its capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 1. Import helper libraries and instantiate credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import sys\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"OPENAI_API_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"OPENAI_API_KEY\"),  \n",
    "  #api_version=\"2024-02-15-preview\"\n",
    "  api_version='2023-05-15',\n",
    ")\n",
    "# set the model deployment name\n",
    "model = os.getenv(\"GPT4_MODEL_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Chat with Model to ask generic question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"Answer the question as truthfully as possible, and if you're unsure of the answer, say \"Sorry, I don't know\" \"\"\"\n",
    "\n",
    "question = \"Who wont the high jump in 2020 Olympics?\"\n",
    "\n",
    "message_text = [\n",
    "  {\"role\":\"system\",\"content\":system_prompt},\n",
    "  {\"role\":\"user\",\"content\":question}]\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = message_text,\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue the conversation by asking a follow up question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue the conversation by asking another question\n",
    "follow_up_question = \"\"\"What is the world record for this event?\"\"\"\n",
    "\n",
    "# Note how we send all of the previous messages in the conversation to the API\n",
    "message_text.append({\"role\":\"assistant\",\"content\":answer})\n",
    "message_text.append({\"role\":\"user\",\"content\":follow_up_question})\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages = message_text,\n",
    ")\n",
    "\n",
    "follow_up_answer = response.choices[0].message.content\n",
    "print(follow_up_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional - Continue the conversation further - experiment. Try changing the first 2 questions too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue the conversation by asking another question"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
