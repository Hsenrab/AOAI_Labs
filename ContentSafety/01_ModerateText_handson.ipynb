{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Azure Content Safety API Handson"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Overview\n",
        "This hands on help you to understand the Content Safety API access and perform text moderation.\n",
        "\n",
        "Note that the Content Safety RestAPI just returns the Categories so more code is needed to turn that into a decision.\n",
        "\n",
        "*Remember that when using Azure OpenAI endpoints Content Safety is built into the calls for free, you would only need to call Content Safety separately like this if you are using a different LLM or are moderating content for a different reason*\n",
        "\n",
        "\n",
        "\n",
        "#### Prerequisite\n",
        "Please complete the 00_Setup.ipynb before running rest of the notebooks"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### 1. Install OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "  > [!NOTE] This step is not necessary if run this notebook on Codespaces or within a Devcontainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674254990318
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%pip install requests\n",
        "%pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os \n",
        "load_dotenv()\n",
        "\n",
        "# Check the environment variables are set and assign them to variables.\n",
        "CONTENT_SAFETY_KEY = os.getenv('CONTENT_SAFETY_KEY')\n",
        "CONTENT_SAFETY_REGION = os.getenv('CONTENT_SAFETY_REGION')\n",
        "CONTENT_SAFETY_ENDPOINT= os.getenv('CONTENT_SAFETY_ENDPOINT')\n",
        "\n",
        "print(CONTENT_SAFETY_KEY)\n",
        "print(CONTENT_SAFETY_ENDPOINT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "#\n",
        "# Copyright (c) Microsoft. All rights reserved.\n",
        "# To learn more, please visit the documentation - Quickstart: Azure Content Safety: https://aka.ms/acsstudiodoc\n",
        "#\n",
        "\n",
        "import enum\n",
        "import json\n",
        "import requests\n",
        "from typing import Union\n",
        "\n",
        "\n",
        "class MediaType(enum.Enum):\n",
        "    Text = 1\n",
        "    Image = 2\n",
        "\n",
        "\n",
        "class Category(enum.Enum):\n",
        "    Hate = 1\n",
        "    SelfHarm = 2\n",
        "    Sexual = 3\n",
        "    Violence = 4\n",
        "\n",
        "\n",
        "class Action(enum.Enum):\n",
        "    Accept = 1\n",
        "    Reject = 2\n",
        "\n",
        "\n",
        "class DetectionError(Exception):\n",
        "    def __init__(self, code: str, message: str) -> None:\n",
        "        \"\"\"\n",
        "        Exception raised when there is an error in detecting the content.\n",
        "\n",
        "        Args:\n",
        "        - code (str): The error code.\n",
        "        - message (str): The error message.\n",
        "        \"\"\"\n",
        "        self.code = code\n",
        "        self.message = message\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return f\"DetectionError(code={self.code}, message={self.message})\"\n",
        "\n",
        "\n",
        "class Decision(object):\n",
        "    def __init__(\n",
        "        self, suggested_action: Action, action_by_category: dict[Category, Action]\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Represents the decision made by the content moderation system.\n",
        "\n",
        "        Args:\n",
        "        - suggested_action (Action): The suggested action to take.\n",
        "        - action_by_category (dict[Category, Action]): The action to take for each category.\n",
        "        \"\"\"\n",
        "        self.suggested_action = suggested_action\n",
        "        self.action_by_category = action_by_category\n",
        "\n",
        "\n",
        "class ContentSafety(object):\n",
        "    def __init__(self, endpoint: str, subscription_key: str, api_version: str) -> None:\n",
        "        \"\"\"\n",
        "        Creates a new ContentSafety instance.\n",
        "\n",
        "        Args:\n",
        "        - endpoint (str): The endpoint URL for the Content Safety API.\n",
        "        - subscription_key (str): The subscription key for the Content Safety API.\n",
        "        - api_version (str): The version of the Content Safety API to use.\n",
        "        \"\"\"\n",
        "        self.endpoint = endpoint\n",
        "        self.subscription_key = subscription_key\n",
        "        self.api_version = api_version\n",
        "\n",
        "    def build_url(self, media_type: MediaType) -> str:\n",
        "        \"\"\"\n",
        "        Builds the URL for the Content Safety API based on the media type.\n",
        "\n",
        "        Args:\n",
        "        - media_type (MediaType): The type of media to analyze.\n",
        "\n",
        "        Returns:\n",
        "        - str: The URL for the Content Safety API.\n",
        "        \"\"\"\n",
        "        if media_type == MediaType.Text:\n",
        "            return f\"{self.endpoint}/contentsafety/text:analyze?api-version={self.api_version}\"\n",
        "        elif media_type == MediaType.Image:\n",
        "            return f\"{self.endpoint}/contentsafety/image:analyze?api-version={self.api_version}\"\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid Media Type {media_type}\")\n",
        "\n",
        "    def build_headers(self) -> dict[str, str]:\n",
        "        \"\"\"\n",
        "        Builds the headers for the Content Safety API request.\n",
        "\n",
        "        Returns:\n",
        "        - dict[str, str]: The headers for the Content Safety API request.\n",
        "        \"\"\"\n",
        "        return {\n",
        "            \"Ocp-Apim-Subscription-Key\": self.subscription_key,\n",
        "            \"Content-Type\": \"application/json\",\n",
        "        }\n",
        "\n",
        "    def build_request_body(\n",
        "        self,\n",
        "        media_type: MediaType,\n",
        "        content: str,\n",
        "        blocklists: list[str],\n",
        "    ) -> dict:\n",
        "        \"\"\"\n",
        "        Builds the request body for the Content Safety API request.\n",
        "\n",
        "        Args:\n",
        "        - media_type (MediaType): The type of media to analyze.\n",
        "        - content (str): The content to analyze.\n",
        "        - blocklists (list[str]): The blocklists to use for text analysis.\n",
        "\n",
        "        Returns:\n",
        "        - dict: The request body for the Content Safety API request.\n",
        "        \"\"\"\n",
        "        if media_type == MediaType.Text:\n",
        "            return {\n",
        "                \"text\": content,\n",
        "                \"blocklistNames\": blocklists,\n",
        "            }\n",
        "        elif media_type == MediaType.Image:\n",
        "            return {\"image\": {\"content\": content}}\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid Media Type {media_type}\")\n",
        "\n",
        "    def detect(\n",
        "        self,\n",
        "        media_type: MediaType,\n",
        "        content: str,\n",
        "        blocklists: list[str] = [],\n",
        "    ) -> dict:\n",
        "        \"\"\"\n",
        "        Detects unsafe content using the Content Safety API.\n",
        "\n",
        "        Args:\n",
        "        - media_type (MediaType): The type of media to analyze.\n",
        "        - content (str): The content to analyze.\n",
        "        - blocklists (list[str]): The blocklists to use for text analysis.\n",
        "\n",
        "        Returns:\n",
        "        - dict: The response from the Content Safety API.\n",
        "        \"\"\"\n",
        "        url = self.build_url(media_type)\n",
        "        headers = self.build_headers()\n",
        "        request_body = self.build_request_body(media_type, content, blocklists)\n",
        "        payload = json.dumps(request_body)\n",
        "\n",
        "        response = requests.post(url, headers=headers, data=payload)\n",
        "        print(response.status_code)\n",
        "        print(response.headers)\n",
        "        print(response.text)\n",
        "\n",
        "        res_content = response.json()\n",
        "\n",
        "        if response.status_code != 200:\n",
        "            raise DetectionError(\n",
        "                res_content[\"error\"][\"code\"], res_content[\"error\"][\"message\"]\n",
        "            )\n",
        "\n",
        "        return res_content\n",
        "\n",
        "    def get_detect_result_by_category(\n",
        "        self, category: Category, detect_result: dict\n",
        "    ) -> Union[int, None]:\n",
        "        \"\"\"\n",
        "        Gets the detection result for the given category from the Content Safety API response.\n",
        "\n",
        "        Args:\n",
        "        - category (Category): The category to get the detection result for.\n",
        "        - detect_result (dict): The Content Safety API response.\n",
        "\n",
        "        Returns:\n",
        "        - Union[int, None]: The detection result for the given category, or None if it is not found.\n",
        "        \"\"\"\n",
        "        category_res = detect_result.get(\"categoriesAnalysis\", None)\n",
        "        for res in category_res:\n",
        "            if category.name == res.get(\"category\", None):\n",
        "                return res\n",
        "        raise ValueError(f\"Invalid Category {category}\")\n",
        "\n",
        "    def make_decision(\n",
        "        self,\n",
        "        detection_result: dict,\n",
        "        reject_thresholds: dict[Category, int],\n",
        "    ) -> Decision:\n",
        "        \"\"\"\n",
        "        Makes a decision based on the Content Safety API response and the specified reject thresholds.\n",
        "        Users can customize their decision-making method.\n",
        "\n",
        "        Args:\n",
        "        - detection_result (dict): The Content Safety API response.\n",
        "        - reject_thresholds (dict[Category, int]): The reject thresholds for each category.\n",
        "\n",
        "        Returns:\n",
        "        - Decision: The decision based on the Content Safety API response and the specified reject thresholds.\n",
        "        \"\"\"\n",
        "        action_result = {}\n",
        "        final_action = Action.Accept\n",
        "        for category, threshold in reject_thresholds.items():\n",
        "            if threshold not in (-1, 0, 2, 4, 6):\n",
        "                raise ValueError(\"RejectThreshold can only be in (-1, 0, 2, 4, 6)\")\n",
        "\n",
        "            cate_detect_res = self.get_detect_result_by_category(\n",
        "                category, detection_result\n",
        "            )\n",
        "            if cate_detect_res is None or \"severity\" not in cate_detect_res:\n",
        "                raise ValueError(f\"Can not find detection result for {category}\")\n",
        "\n",
        "            severity = cate_detect_res[\"severity\"]\n",
        "            action = (\n",
        "                Action.Reject\n",
        "                if threshold != -1 and severity >= threshold\n",
        "                else Action.Accept\n",
        "            )\n",
        "            action_result[category] = action\n",
        "            if action.value > final_action.value:\n",
        "                final_action = action\n",
        "\n",
        "        if (\n",
        "            \"blocklistsMatch\" in detection_result\n",
        "            and detection_result[\"blocklistsMatch\"]\n",
        "            and len(detection_result[\"blocklistsMatch\"]) > 0\n",
        "        ):\n",
        "            final_action = Action.Reject\n",
        "\n",
        "        print(final_action.name)\n",
        "        print(action_result)\n",
        "\n",
        "        return Decision(final_action, action_result)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'CONTENT_SAFETY_ENDPOINT' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m api_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2024-09-01\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Initialize the ContentSafety object\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m content_safety \u001b[38;5;241m=\u001b[39m ContentSafety(\u001b[43mCONTENT_SAFETY_ENDPOINT\u001b[49m, CONTENT_SAFETY_KEY, api_version)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Set the media type and blocklists\u001b[39;00m\n\u001b[1;32m      7\u001b[0m media_type \u001b[38;5;241m=\u001b[39m MediaType\u001b[38;5;241m.\u001b[39mText\n",
            "\u001b[0;31mNameError\u001b[0m: name 'CONTENT_SAFETY_ENDPOINT' is not defined"
          ]
        }
      ],
      "source": [
        "api_version = \"2024-09-01\"\n",
        "\n",
        "# Initialize the ContentSafety object\n",
        "content_safety = ContentSafety(CONTENT_SAFETY_ENDPOINT, CONTENT_SAFETY_KEY, api_version)\n",
        "\n",
        "# Set the media type and blocklists\n",
        "media_type = MediaType.Text\n",
        "blocklists = []\n",
        "\n",
        "# Set the content to be tested\n",
        "content = \"I have a cat called Whiskers.\"\n",
        "\n",
        "# Detect content safety\n",
        "detection_result = content_safety.detect(media_type, content, blocklists)\n",
        "\n",
        "# Set the reject thresholds for each category\n",
        "reject_thresholds = {\n",
        "    Category.Hate: 4,\n",
        "    Category.SelfHarm: 4,\n",
        "    Category.Sexual: 4,\n",
        "    Category.Violence: 4,\n",
        "}\n",
        "\n",
        "# Make a decision based on the detection result and reject thresholds\n",
        "decision_result = content_safety.make_decision(detection_result, reject_thresholds)\n",
        "\n",
        "print(\"Suggested Decision: \" + str(decision_result.suggested_action))\n",
        "print(\"Categories: \" + str(decision_result.action_by_category))\n"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python openai_env_upskilling",
      "language": "python",
      "name": "openai_env_upskilling"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
