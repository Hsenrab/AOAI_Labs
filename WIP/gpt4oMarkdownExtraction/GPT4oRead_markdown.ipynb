{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install packages and set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install azure-search-documents==11.5.1 --quiet\n",
    "#%pip install azure-identity --quiet\n",
    "#%pip install python-dotenv --quiet\n",
    "#%pip install pymupdf --quiet\n",
    "%pip install openai --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credentials\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "# Check the environment variables are set and assign them to variables.\n",
    "AI_SEARCH_ENDPOINT = os.getenv('AI_SEARCH_ENDPOINT')\n",
    "AI_SEARCH_KEY = os.getenv('AI_SEARCH_KEY')\n",
    "\n",
    "# Ensure all required environment variables are set\n",
    "if not all([AI_SEARCH_ENDPOINT, AI_SEARCH_KEY]):\n",
    "    missing_vars = [var for var, val in zip(['AI_SEARCH_ENDPOINT', 'AI_SEARCH_KEY'], \n",
    "                                            [AI_SEARCH_ENDPOINT, AI_SEARCH_KEY]) if not val]\n",
    "    raise ValueError(f\"Environment variables {', '.join(missing_vars)} must be set.\")\n",
    "\n",
    "# Print the environment variables\n",
    "print(f\"AI_SEARCH_ENDPOINT: {AI_SEARCH_ENDPOINT}\")\n",
    "print(f\"AI_SEARCH_KEY: {AI_SEARCH_KEY}\")\n",
    "\n",
    "index_name: str = \"soc_index\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert PDF to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "import uuid\n",
    "\n",
    "def convert_pdf_to_images(pdf_path, blob_connection_string=None, container_name=None):\n",
    "    \"\"\"\n",
    "    Converts each page of a PDF into JPEG images and saves them in a directory named after the PDF file.\n",
    "    Optionally uploads the images to an Azure Blob Storage container.\n",
    "\n",
    "    Args:\n",
    "    - pdf_path (str): Path to the PDF file.\n",
    "    - blob_connection_string (str, optional): Azure Blob Storage connection string.\n",
    "    - container_name (str, optional): Name of the Azure Blob Storage container.\n",
    "\n",
    "    Returns:\n",
    "    - list: List of image file paths saved.\n",
    "    \"\"\"\n",
    "    # Create a directory based on the PDF filename in the same directory as the original file\n",
    "    pdf_name = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "    output_dir = os.path.join(os.path.dirname(pdf_path), f\"{pdf_name}_images\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Open the PDF file\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    saved_image_paths = []\n",
    "\n",
    "    # Convert each page of the PDF into images\n",
    "    for page_num in range(len(pdf_document)):\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        pix = page.get_pixmap()\n",
    "        image_path = os.path.join(output_dir, f'page{page_num}.jpg')\n",
    "        pix.save(image_path)\n",
    "        saved_image_paths.append(image_path)\n",
    "\n",
    "        # Upload to Azure Blob Storage if connection string and container name are provided\n",
    "        if blob_connection_string and container_name:\n",
    "            blob_service_client = BlobServiceClient.from_connection_string(blob_connection_string)\n",
    "            container_client = blob_service_client.get_container_client(container_name)\n",
    "            if not container_client.exists():\n",
    "                container_client.create_container()\n",
    "            blob_client = container_client.get_blob_client(blob=f'{pdf_name}/page{page_num}.jpg')\n",
    "            with open(image_path, \"rb\") as data:\n",
    "                blob_client.upload_blob(data, overwrite=True)\n",
    "    \n",
    "    return saved_image_paths\n",
    "\n",
    "# Find out the current working directory\n",
    "\n",
    "BLOB_STORAGE_ACCOUNT_CONNECTION_STRING = os.getenv('BLOB_STORAGE_ACCOUNT_CONNECTION_STRING')\n",
    "\n",
    "pdf_path = \"data\\Azure DevOps - SOC 2 Type II Report (2023-10-01-to 2024-09-30).pdf\"\n",
    "container_name = \"frompdf\"\n",
    "image_paths = convert_pdf_to_images(pdf_path)\n",
    "print(f\"Converted images saved at: {image_paths}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a documents payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from mimetypes import guess_type\n",
    "\n",
    "def local_image_to_data_url(image_path):\n",
    "    \"\"\"\n",
    "    Get the url of a local image\n",
    "    \"\"\"\n",
    "    mime_type, _ = guess_type(image_path)\n",
    "\n",
    "    if mime_type is None:\n",
    "        mime_type = \"application/octet-stream\"\n",
    "\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        base64_encoded_data = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "    return f\"data:{mime_type};base64,{base64_encoded_data}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "import json\n",
    "\n",
    "def gpt4o_imagefile(image_file):\n",
    "    \"\"\"\n",
    "    Gpt-4o model\n",
    "    \"\"\"\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "    You are an AI assistance that extracts text from the image. You are especially good at extracting tables.\n",
    "    When you see a table\n",
    "    You format the table like this:\n",
    "    \n",
    "    Monthly Savings\n",
    "    | Month    | Savings |Details      |\n",
    "    | -------- | ------- |------------ |\n",
    "    | January  | $250    | for holiday |\n",
    "    | February | $80     | pension     |\n",
    "    | March    | $420    | new cat     |\n",
    "\"\"\"\n",
    "    \n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=os.environ['OPENAI_API_ENDPOINT'],\n",
    "        api_key=os.environ['OPENAI_API_KEY'],\n",
    "        api_version='2023-05-15',\n",
    "        )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": \"Extract text from the image\"},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": local_image_to_data_url(image_file)},\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "# Extract data from each image and save to JSON\n",
    "start_page = 120  # specify the start page number\n",
    "end_page = 201 # specify the end page number\n",
    "extracted_data=[]\n",
    "\n",
    "\n",
    "for image_path in image_paths[start_page:end_page]:\n",
    "    data = gpt4o_imagefile(image_path)\n",
    "    filename_only = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    extracted_data.append([data, filename_only])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (text, filename_only) in enumerate(extracted_data):\n",
    "    filename = f\"extracted_data_{filename_only}.md\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(text)\n",
    "    print(f\"Wrote extracted text to -> {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
    "\n",
    "\n",
    "# Initialize the BlobServiceClient\n",
    "blob_service_client = BlobServiceClient.from_connection_string(BLOB_STORAGE_ACCOUNT_CONNECTION_STRING)\n",
    "container_name = \"toindexsoc\"\n",
    "\n",
    "# Get the container client\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "# Ensure the container exists\n",
    "if not container_client.exists():\n",
    "    container_client.create_container()\n",
    "\n",
    "# Upload each element in the extracted_data list as a separate markdown file\n",
    "for i, (text, filename_only) in enumerate(extracted_data):\n",
    "    blob_name = f\"extracted_data_{filename_only}.md\"\n",
    "    blob_client = container_client.get_blob_client(blob_name)\n",
    "    \n",
    "    # Upload the markdown text to Blob Storage\n",
    "    blob_client.upload_blob(text, overwrite=True)\n",
    "    \n",
    "    print(f\"Extracted markdown uploaded to blob storage at: {blob_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes import SearchIndexerClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndexerDataContainer,\n",
    "    SearchIndexerDataSourceConnection\n",
    ")\n",
    "\n",
    "# Create a data source \n",
    "indexer_client = SearchIndexerClient(endpoint=AI_SEARCH_ENDPOINT, credential=AzureKeyCredential(AI_SEARCH_KEY))\n",
    "container = SearchIndexerDataContainer(name=container_name)\n",
    "data_source_connection = SearchIndexerDataSourceConnection(\n",
    "    name=container_name+\"-connection\",\n",
    "    type=\"azureblob\",\n",
    "    connection_string=BLOB_STORAGE_ACCOUNT_CONNECTION_STRING,\n",
    "    container=container\n",
    ")\n",
    "data_source = indexer_client.create_or_update_data_source_connection(data_source_connection)\n",
    "\n",
    "print(f\"Data source '{data_source.name}' created or updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    "    AzureOpenAIVectorizer,\n",
    "    AzureOpenAIVectorizerParameters,\n",
    "    SearchIndex\n",
    ")\n",
    "\n",
    "AZURE_SEARCH_CREDENTIAL = AzureKeyCredential(AI_SEARCH_KEY)\n",
    "# Create a search index  \n",
    "index_name = container_name+\"-index\"\n",
    "index_client = SearchIndexClient(endpoint=AI_SEARCH_ENDPOINT, credential=AZURE_SEARCH_CREDENTIAL)  \n",
    "fields = [\n",
    "    SearchField(name=\"parent_id\", type=SearchFieldDataType.String),  \n",
    "    SearchField(name=\"title\", type=SearchFieldDataType.String),\n",
    "    SearchField(name=\"chunk_id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True, analyzer_name=\"keyword\"),  \n",
    "    SearchField(name=\"chunk\", type=SearchFieldDataType.String, sortable=False, filterable=False, facetable=False),  \n",
    "    SearchField(name=\"text_vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), vector_search_dimensions=1536, vector_search_profile_name=\"myHnswProfile\")\n",
    "    ]  \n",
    "  \n",
    "# Configure the vector search configuration  \n",
    "vector_search = VectorSearch(  \n",
    "    algorithms=[  \n",
    "        HnswAlgorithmConfiguration(name=\"myHnsw\"),\n",
    "    ],  \n",
    "    profiles=[  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"myHnswProfile\",  \n",
    "            algorithm_configuration_name=\"myHnsw\",  \n",
    "            vectorizer_name=\"myOpenAI\",  \n",
    "        )\n",
    "    ],  \n",
    "    vectorizers=[  \n",
    "        AzureOpenAIVectorizer(  \n",
    "            vectorizer_name=\"myOpenAI\",  \n",
    "            kind=\"azureOpenAI\",  \n",
    "            parameters=AzureOpenAIVectorizerParameters(  \n",
    "                resource_url=OPENAI_API_ENDPOINT,  \n",
    "                deployment_name=os.getenv(\"EMBEDDINGS_MODEL_NAME\"),\n",
    "                model_name=\"text-embedding-ada-002\",\n",
    "                api_key=OPENAI_API_KEY\n",
    "            ),\n",
    "        ),  \n",
    "    ], \n",
    ")  \n",
    "  \n",
    "# Create the search index\n",
    "index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search)  \n",
    "result = index_client.create_or_update_index(index)  \n",
    "print(f\"{result.name} created\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    SplitSkill,\n",
    "    InputFieldMappingEntry,\n",
    "    OutputFieldMappingEntry,\n",
    "    AzureOpenAIEmbeddingSkill,\n",
    "    EntityRecognitionSkill,\n",
    "    SearchIndexerIndexProjection,\n",
    "    SearchIndexerIndexProjectionSelector,\n",
    "    SearchIndexerIndexProjectionsParameters,\n",
    "    IndexProjectionMode,\n",
    "    SearchIndexerSkillset,\n",
    "    CognitiveServicesAccountKey,\n",
    "    WebApiSkill\n",
    ")\n",
    "\n",
    "AZURE_AI_KEY = os.getenv('AZURE_AI_KEY')\n",
    "\n",
    "\n",
    "# Create a skillset  \n",
    "skillset_name = container_name+\"-skillset\"\n",
    "\n",
    "split_skill = SplitSkill(  \n",
    "    description=\"Split skill to chunk documents\",  \n",
    "    text_split_mode=\"pages\",  \n",
    "    context=\"/document\",  \n",
    "    maximum_page_length=20000,  \n",
    "    page_overlap_length=500,  \n",
    "    inputs=[  \n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/content\"),  \n",
    "    ],  \n",
    "    outputs=[  \n",
    "        OutputFieldMappingEntry(name=\"textItems\", target_name=\"pages\")  \n",
    "    ],  \n",
    ")\n",
    "\n",
    "embedding_skill = AzureOpenAIEmbeddingSkill(  \n",
    "    description=\"Skill to generate embeddings via Azure OpenAI\",  \n",
    "    context=\"/document/pages/*\",\n",
    "    resource_url=OPENAI_API_ENDPOINT,\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    deployment_name=os.getenv(\"EMBEDDINGS_MODEL_NAME\"),\n",
    "    model_name=\"text-embedding-ada-002\",\n",
    "    dimensions=1536,\n",
    "    inputs=[  \n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/pages/*\"),  \n",
    "    ],  \n",
    "    outputs=[  \n",
    "        OutputFieldMappingEntry(name=\"embedding\", target_name=\"text_vector\")  \n",
    "    ],  \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "index_projections = SearchIndexerIndexProjection(  \n",
    "    selectors=[  \n",
    "        SearchIndexerIndexProjectionSelector(  \n",
    "            target_index_name=index_name,  \n",
    "            parent_key_field_name=\"parent_id\",  \n",
    "            source_context=\"/document/pages/*\",  \n",
    "            mappings=[  \n",
    "                InputFieldMappingEntry(name=\"chunk\", source=\"/document/pages/*\"),  \n",
    "                InputFieldMappingEntry(name=\"text_vector\", source=\"/document/pages/*/text_vector\"),\n",
    "                InputFieldMappingEntry(name=\"title\", source=\"/document/metadata_storage_name\"),  \n",
    "            ],  \n",
    "        ),  \n",
    "    ],  \n",
    "    parameters=SearchIndexerIndexProjectionsParameters(  \n",
    "        projection_mode=IndexProjectionMode.SKIP_INDEXING_PARENT_DOCUMENTS  \n",
    "    ),  \n",
    ") \n",
    "\n",
    "cognitive_services_account = CognitiveServicesAccountKey(key=AZURE_AI_KEY)\n",
    "\n",
    "\n",
    "skills = [split_skill, embedding_skill]\n",
    "\n",
    "skillset = SearchIndexerSkillset(  \n",
    "    name=skillset_name,  \n",
    "    description=\"Skillset to chunk documents and generating embeddings\",  \n",
    "    skills=skills,\n",
    "    index_projection=index_projections,\n",
    "    cognitive_services_account=cognitive_services_account\n",
    ")\n",
    "\n",
    "client = SearchIndexerClient(endpoint=AI_SEARCH_ENDPOINT, credential=AZURE_SEARCH_CREDENTIAL)  \n",
    "client.create_or_update_skillset(skillset)  \n",
    "print(f\"{skillset.name} created\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndexer,\n",
    "    FieldMapping\n",
    ")\n",
    "\n",
    "# Create an indexer \n",
    "indexer_name = container_name+\"-indexer\" \n",
    "\n",
    "indexer_parameters = None\n",
    "\n",
    "indexer = SearchIndexer(  \n",
    "    name=indexer_name,  \n",
    "    description=\"Indexer to index documents and generate embeddings\",  \n",
    "    skillset_name=skillset_name,  \n",
    "    target_index_name=index_name,  \n",
    "    data_source_name=data_source.name,\n",
    "    # Map the metadata_storage_name field to the title field in the index to display the PDF title in the search results  \n",
    "    field_mappings=[FieldMapping(source_field_name=\"metadata_storage_name\", target_field_name=\"title\")],\n",
    "    parameters=indexer_parameters\n",
    ")  \n",
    "\n",
    "# Create and run the indexer  \n",
    "indexer_client = SearchIndexerClient(endpoint=AI_SEARCH_ENDPOINT, credential=AZURE_SEARCH_CREDENTIAL) \n",
    "\n",
    "indexer_result = indexer_client.create_or_update_indexer(indexer)\n",
    "\n",
    "\n",
    "print(f' {indexer_name} is created and running. Give the indexer a few minutes before running a query.')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "promtpflow_examples",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
