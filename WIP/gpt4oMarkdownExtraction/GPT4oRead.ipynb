{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a search index in Azure AI Search using the Azure SDK for Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "This notebook steps through creating, loading, and querying an index in Azure AI Search index by calling the azure-search-documents library in the Azure SDK for Python. \n",
    "\n",
    "## Prerequisites\n",
    "*If you are doing all the notebooks then this setup is coverd in 00_Setup*\n",
    "- Create Azure AI Search [instructions here](https://learn.microsoft.com/azure/search/search-create-service-portal) \n",
    "(You may have already created them in previous notebooks)\n",
    "  - Basic tier or higher is recommended.\n",
    "  - Choose the same region as Azure OpenAI.\n",
    "  - Enable semantic ranking.\n",
    "  - Enable a system identity for Azure AI Search. - Settings / Identity / System Assigned / Enable\n",
    "  - Update the .env file with AI_SEARCH_KEY  (Use admin keys - In the portal go to resources then Settings, Keys on the left.)\n",
    "  - Update the .env file with AI_SEARCH_ENDPOINT  (Overview page - url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install packages and set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install azure-search-documents==11.5.1 --quiet\n",
    "#%pip install azure-identity --quiet\n",
    "#%pip install python-dotenv --quiet\n",
    "#%pip install pymupdf --quiet\n",
    "%pip install openai --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credentials\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "# Check the environment variables are set and assign them to variables.\n",
    "AI_SEARCH_ENDPOINT = os.getenv('AI_SEARCH_ENDPOINT')\n",
    "AI_SEARCH_KEY = os.getenv('AI_SEARCH_KEY')\n",
    "\n",
    "# Ensure all required environment variables are set\n",
    "if not all([AI_SEARCH_ENDPOINT, AI_SEARCH_KEY]):\n",
    "    missing_vars = [var for var, val in zip(['AI_SEARCH_ENDPOINT', 'AI_SEARCH_KEY'], \n",
    "                                            [AI_SEARCH_ENDPOINT, AI_SEARCH_KEY]) if not val]\n",
    "    raise ValueError(f\"Environment variables {', '.join(missing_vars)} must be set.\")\n",
    "\n",
    "# Print the environment variables\n",
    "print(f\"AI_SEARCH_ENDPOINT: {AI_SEARCH_ENDPOINT}\")\n",
    "print(f\"AI_SEARCH_KEY: {AI_SEARCH_KEY}\")\n",
    "\n",
    "index_name: str = \"soc_index\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "credential = AzureKeyCredential(AI_SEARCH_KEY)\n",
    "\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchField,\n",
    "    SimpleField,\n",
    "    SearchFieldDataType,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    "    AzureOpenAIVectorizer,\n",
    "    AzureOpenAIVectorizerParameters,\n",
    "    SearchIndex,\n",
    "    SearchableField\n",
    ")\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "OPENAI_API_ENDPOINT = os.getenv('OPENAI_API_ENDPOINT')\n",
    "\n",
    "# Create a search schema\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=AI_SEARCH_ENDPOINT, credential=credential)\n",
    "fields = [\n",
    "    SimpleField(name=\"parent_id\", type=SearchFieldDataType.String, key=False, searchable=True, filterable=True, retrievable=True, stored=True, sortable=True, facetable=True),\n",
    "    SearchableField(name=\"title\", type=SearchFieldDataType.String, key=False, searchable=True, filterable=True, retrievable=True, stored=True, sortable=True, facetable=True),\n",
    "    SearchableField(name=\"chunk_id\", type=SearchFieldDataType.String, key=True, searchable=True, filterable=True, retrievable=True, stored=True, sortable=True, facetable=True, analyzer_name=\"keyword\"),\n",
    "    SearchableField(name=\"chunk\", type=SearchFieldDataType.String, key=False, searchable=True, filterable=False, retrievable=True, stored=True, sortable=False, facetable=False),\n",
    "    SearchableField(name=\"filepath\", type=SearchFieldDataType.String, key=False, searchable=True, filterable=True, retrievable=True, stored=True, sortable=True, facetable=True),\n",
    "    SearchableField(name=\"header_1\", type=SearchFieldDataType.String, key=False, searchable=True, filterable=False, retrievable=True, stored=True, sortable=False, facetable=False),\n",
    "    SearchableField(name=\"header_2\", type=SearchFieldDataType.String, key=False, searchable=True, filterable=False, retrievable=True, stored=True, sortable=False, facetable=False),\n",
    "    SearchableField(name=\"header_3\", type=SearchFieldDataType.String, key=False, searchable=True, filterable=False, retrievable=True, stored=True, sortable=False, facetable=False)\n",
    "]\n",
    "\n",
    "scoring_profiles = []\n",
    "suggester = []\n",
    "\n",
    "# Configure the vector search configuration  \n",
    "vector_search = VectorSearch(  \n",
    "    algorithms=[  \n",
    "        HnswAlgorithmConfiguration(name=\"myHnsw\"),\n",
    "    ],  \n",
    "    profiles=[  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"myHnswProfile\",  \n",
    "            algorithm_configuration_name=\"myHnsw\",  \n",
    "            vectorizer_name=\"myOpenAI\",  \n",
    "        )\n",
    "    ],  \n",
    "    vectorizers=[  \n",
    "        AzureOpenAIVectorizer(  \n",
    "            vectorizer_name=\"myOpenAI\",  \n",
    "            kind=\"azureOpenAI\",  \n",
    "            parameters=AzureOpenAIVectorizerParameters(  \n",
    "                resource_url=OPENAI_API_ENDPOINT,  \n",
    "                deployment_name=os.getenv(\"EMBEDDINGS_MODEL_NAME\"),\n",
    "                model_name=\"text-embedding-ada-002\",\n",
    "                api_key=OPENAI_API_KEY\n",
    "            ),\n",
    "        ),  \n",
    "    ], \n",
    ")  \n",
    "\n",
    "\n",
    "# Create the search index=\n",
    "index = SearchIndex(name=index_name, fields=fields)\n",
    "result = index_client.create_or_update_index(index)\n",
    "print(f' {result.name} created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert PDF to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "import uuid\n",
    "\n",
    "def convert_pdf_to_images(pdf_path, blob_connection_string=None, container_name=None):\n",
    "    \"\"\"\n",
    "    Converts each page of a PDF into JPEG images and saves them in a directory named after the PDF file.\n",
    "    Optionally uploads the images to an Azure Blob Storage container.\n",
    "\n",
    "    Args:\n",
    "    - pdf_path (str): Path to the PDF file.\n",
    "    - blob_connection_string (str, optional): Azure Blob Storage connection string.\n",
    "    - container_name (str, optional): Name of the Azure Blob Storage container.\n",
    "\n",
    "    Returns:\n",
    "    - list: List of image file paths saved.\n",
    "    \"\"\"\n",
    "    # Create a directory based on the PDF filename in the same directory as the original file\n",
    "    pdf_name = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "    output_dir = os.path.join(os.path.dirname(pdf_path), f\"{pdf_name}_images\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Open the PDF file\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    saved_image_paths = []\n",
    "\n",
    "    # Convert each page of the PDF into images\n",
    "    for page_num in range(len(pdf_document)):\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        pix = page.get_pixmap()\n",
    "        image_path = os.path.join(output_dir, f'page{page_num}.jpg')\n",
    "        pix.save(image_path)\n",
    "        saved_image_paths.append(image_path)\n",
    "\n",
    "        # Upload to Azure Blob Storage if connection string and container name are provided\n",
    "        if blob_connection_string and container_name:\n",
    "            blob_service_client = BlobServiceClient.from_connection_string(blob_connection_string)\n",
    "            container_client = blob_service_client.get_container_client(container_name)\n",
    "            if not container_client.exists():\n",
    "                container_client.create_container()\n",
    "            blob_client = container_client.get_blob_client(blob=f'{pdf_name}/page{page_num}.jpg')\n",
    "            with open(image_path, \"rb\") as data:\n",
    "                blob_client.upload_blob(data, overwrite=True)\n",
    "    \n",
    "    return saved_image_paths\n",
    "\n",
    "# Find out the current working directory\n",
    "\n",
    "BLOB_STORAGE_ACCOUNT_CONNECTION_STRING = os.getenv('BLOB_STORAGE_ACCOUNT_CONNECTION_STRING')\n",
    "\n",
    "pdf_path = \"data\\Azure DevOps - SOC 2 Type II Report (2023-10-01-to 2024-09-30).pdf\"\n",
    "container_name = \"frompdf\"\n",
    "image_paths = convert_pdf_to_images(pdf_path)\n",
    "print(f\"Converted images saved at: {image_paths}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a documents payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from mimetypes import guess_type\n",
    "\n",
    "def local_image_to_data_url(image_path):\n",
    "    \"\"\"\n",
    "    Get the url of a local image\n",
    "    \"\"\"\n",
    "    mime_type, _ = guess_type(image_path)\n",
    "\n",
    "    if mime_type is None:\n",
    "        mime_type = \"application/octet-stream\"\n",
    "\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        base64_encoded_data = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "    return f\"data:{mime_type};base64,{base64_encoded_data}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "import json\n",
    "\n",
    "def gpt4o_imagefile(image_file):\n",
    "    \"\"\"\n",
    "    Gpt-4o model\n",
    "    \"\"\"\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "    You are an AI assistance that extracts text from the image. You are especially good at extracting tables.\n",
    "    When you see a table such as:\n",
    "    \n",
    "    Monthly Savings\n",
    "    | Month    | Savings |Details |\n",
    "    | -------- | ------- |------- \n",
    "    | January  | $250    | for holiday    |\n",
    "    | February | $80     | pension   |\n",
    "    | March    | $420    | new cat   |\n",
    "\n",
    "    \n",
    "    You format the json like this:\n",
    "    {\n",
    "    \"Title\": \"Monthly Savings\",\n",
    "    \"Data\": [\n",
    "        {\n",
    "            \"Month\": \"January\",\n",
    "            \"Savings\": \"$250\",\n",
    "            \"Details\": \"for holiday\"\n",
    "        },\n",
    "        {\n",
    "            \"Month\": \"February\",\n",
    "            \"Savings\": \"$80\",\n",
    "            \"Details\": \"pension\"\n",
    "        },\n",
    "        {\n",
    "            \"Month\": \"March\",\n",
    "            \"Savings\": \"$420\",\n",
    "            \"Details\": \"new cat\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "    \n",
    "    So that each row is a dictionary with the column name as the key and the cell value as the value.\n",
    "\"\"\"\n",
    "    \n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=os.environ['OPENAI_API_ENDPOINT'],\n",
    "        api_key=os.environ['OPENAI_API_KEY'],\n",
    "        api_version='2023-05-15',\n",
    "        )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": \"Extract text from the image\"},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": local_image_to_data_url(image_file)},\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    \n",
    "    return json.loads(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Extract data from each image and save to JSON\n",
    "start_page = 170  # specify the start page number\n",
    "end_page = 175 # specify the end page number\n",
    "extracted_data=[]\n",
    "\n",
    "\n",
    "for image_path in image_paths[start_page:end_page]:\n",
    "    data = gpt4o_imagefile(image_path)\n",
    "    extracted_data.append(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save extracted data to a JSON file\n",
    "\n",
    "with open(\"extracted_data.json\", \"w\") as json_file:\n",
    "    json.dump(extracted_data, json_file, indent=4)\n",
    "\n",
    "print(\"Data extracted and saved to extracted_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
    "import json\n",
    "\n",
    "# Initialize the BlobServiceClient\n",
    "blob_service_client = BlobServiceClient.from_connection_string(BLOB_STORAGE_ACCOUNT_CONNECTION_STRING)\n",
    "\n",
    "# Get the container client\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "# Ensure the container exists\n",
    "if not container_client.exists():\n",
    "    container_client.create_container()\n",
    "\n",
    "# Upload each element in the extracted_data list as a separate JSON file\n",
    "for i, data in enumerate(extracted_data):\n",
    "    # Define the blob name and path\n",
    "    blob_name = f\"json/extracted_data_{i}.json\"\n",
    "    blob_client = container_client.get_blob_client(blob_name)\n",
    "    \n",
    "    # Upload the JSON data to the blob\n",
    "    blob_client.upload_blob(json.dumps(data), overwrite=True)\n",
    "    \n",
    "    print(f\"Extracted data uploaded to blob storage at: {blob_name}\")\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_client = SearchClient(endpoint=AI_SEARCH_ENDPOINT,\n",
    "                      index_name=index_name,\n",
    "                      credential=credential)\n",
    "try:\n",
    "    result = search_client.upload_documents(documents=documents)\n",
    "    print(\"Upload of new document succeeded: {}\".format(result[0].succeeded))\n",
    "except Exception as ex:\n",
    "    print (ex.message)\n",
    "\n",
    "    index_client = SearchIndexClient(\n",
    "    endpoint=AI_SEARCH_ENDPOINT, credential=credential)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run your first query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run an empty query (returns selected fields, all documents)\n",
    "results =  search_client.search(query_type='simple',\n",
    "    search_text=\"*\" ,\n",
    "    select='HotelName,Description',\n",
    "    include_total_count=True)\n",
    "\n",
    "print ('Total Documents Matching Query:', results.get_count())\n",
    "for result in results:\n",
    "    print(result[\"@search.score\"])\n",
    "    print(result[\"HotelName\"])\n",
    "    print(f\"Description: {result['Description']}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a term query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a term query\n",
    "results =  search_client.search(query_type='simple',\n",
    "    search_text=\"wifi\" ,\n",
    "    select='HotelName,Description,Tags',\n",
    "    include_total_count=True)\n",
    "\n",
    "print ('Total Documents Matching Query:', results.get_count())\n",
    "for result in results:\n",
    "    print(result[\"@search.score\"])\n",
    "    print(result[\"HotelName\"])\n",
    "    print(f\"Description: {result['Description']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a filter\n",
    "results = search_client.search(\n",
    "    search_text=\"hotels\", \n",
    "    select='HotelId,HotelName,Rating', \n",
    "    filter='Rating gt 4', \n",
    "    order_by='Rating desc')\n",
    "\n",
    "for result in results:\n",
    "    print(\"{}: {} - {} rating\".format(result[\"HotelId\"], result[\"HotelName\"], result[\"Rating\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scope a query to specific searchable fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = search_client.search(\n",
    "    search_text=\"sublime\", \n",
    "    search_fields=['HotelName'], \n",
    "    select='HotelId,HotelName')\n",
    "\n",
    "for result in results:\n",
    "    print(\"{}: {}\".format(result[\"HotelId\"], result[\"HotelName\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return facets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return facets\n",
    "results = search_client.search(search_text=\"*\", facets=[\"Category\"])\n",
    "\n",
    "facets = results.get_facets()\n",
    "\n",
    "for facet in facets[\"Category\"]:\n",
    "    print(\"    {}\".format(facet))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look up a document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look up a specific document by ID\n",
    "result = search_client.get_document(key=\"3\")\n",
    "\n",
    "print(\"Details for hotel '3' are:\")\n",
    "print(\"Name: {}\".format(result[\"HotelName\"]))\n",
    "print(\"Rating: {}\".format(result[\"Rating\"]))\n",
    "print(\"Category: {}\".format(result[\"Category\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocomplete a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autocomplete a query\n",
    "search_suggestion = 'sa'\n",
    "results = search_client.autocomplete(\n",
    "    search_text=search_suggestion, \n",
    "    suggester_name=\"sg\",\n",
    "    mode='twoTerms')\n",
    "\n",
    "print(\"Autocomplete for:\", search_suggestion)\n",
    "for result in results:\n",
    "    print (result['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## See your resource in the portal.\n",
    "\n",
    "Go to your Search resource then from menu Search Management / Indexes  \n",
    "See the new index there that you have created. \n",
    "Click into it, you can also test the search manually here.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "If you are finished with this index, you can delete it by running the following lines. Deleting unnecessary indexes frees up space for stepping through more quickstarts and tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    result = index_client.delete_index(index_name)\n",
    "    print ('Index', index_name, 'Deleted')\n",
    "except Exception as ex:\n",
    "    print (ex)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the index deletion by running the following script that lists all of the indexes on your search service. If hotels-quickstart is not listed, you've successfully deleted the index and have completed this quickstart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    result = index_client.get_index(index_name)\n",
    "    print (result)\n",
    "except Exception as ex:\n",
    "    print (ex)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "promtpflow_examples",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
