{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv\n",
    "%pip install azure-search-documents==11.5.1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get the directory of the currently running file\n",
    "file_dir = \"C:\\\\Users\\\\hannahhowell\\\\OneDrive - Microsoft\\\\Documents\\Git\\\\AOAI_Labs\\\\AzureAISearchLab\"\n",
    "# Get the current working directory\n",
    "current_cwd = os.getcwd()\n",
    "\n",
    "# Check if the current working directory is the same as the file directory\n",
    "if current_cwd != file_dir:\n",
    "    # Change the current working directory to the file directory\n",
    "    os.chdir(file_dir)\n",
    "    print(f\"Changed current working directory to: {file_dir}\")\n",
    "else:\n",
    "    print(\"Already in the correct directory.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Set container name to name of newly created container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container_name = \"pdfscompiancecatalyst\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credentials\n",
    "from dotenv import load_dotenv\n",
    "import os \n",
    "load_dotenv()\n",
    "\n",
    "# Check the environment variables are set and assign them to variables.\n",
    "AI_SEARCH_ENDPOINT = os.getenv('AI_SEARCH_ENDPOINT')\n",
    "AI_SEARCH_KEY = os.getenv('AI_SEARCH_KEY')\n",
    "\n",
    "BLOB_STORAGE_ACCOUNT_CONNECTION_STRING = os.getenv('BLOB_STORAGE_ACCOUNT_CONNECTION_STRING')\n",
    "GENAI_CUSTOMSKILL_FUNCTION_URL= os.getenv('GENAI_CUSTOMSKILL_FUNCTION_URL')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "OPENAI_API_ENDPOINT = os.getenv('OPENAI_API_ENDPOINT')\n",
    "\n",
    "AZURE_AI_KEY = os.getenv('AZURE_AI_KEY')\n",
    "\n",
    "# Ensure all required environment variables are set\n",
    "if not all([AI_SEARCH_ENDPOINT, AI_SEARCH_KEY, BLOB_STORAGE_ACCOUNT_CONNECTION_STRING, OPENAI_API_KEY, OPENAI_API_ENDPOINT, AZURE_AI_KEY]):\n",
    "    missing_vars = [var for var, val in zip(['AI_SEARCH_ENDPOINT', 'AI_SEARCH_KEY', 'BLOB_STORAGE_ACCOUNT_CONNECTION_STRING', 'OPENAI_API_KEY', 'OPENAI_API_ENDPOINT', 'AZURE_AI_KEY'], \n",
    "                                            [AI_SEARCH_ENDPOINT, AI_SEARCH_KEY, BLOB_STORAGE_ACCOUNT_CONNECTION_STRING, OPENAI_API_KEY, OPENAI_API_ENDPOINT, AZURE_AI_KEY]) if not val]\n",
    "    raise ValueError(f\"Environment variables {', '.join(missing_vars)} must be set.\")\n",
    "\n",
    "# Print the environment variables\n",
    "print(f\"AI_SEARCH_ENDPOINT: {AI_SEARCH_ENDPOINT}\")\n",
    "print(f\"AI_SEARCH_KEY: {AI_SEARCH_KEY}\")\n",
    "print(f\"BLOB_STORAGE_ACCOUNT_CONNECTION_STRING: {BLOB_STORAGE_ACCOUNT_CONNECTION_STRING}\")\n",
    "print(f\"OPENAI_API_KEY: {OPENAI_API_KEY}\")\n",
    "print(f\"OPENAI_API_ENDPOINT: {OPENAI_API_ENDPOINT}\")\n",
    "print(f\"AZURE_AI_KEY: {AZURE_AI_KEY}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    "    AzureOpenAIVectorizer,\n",
    "    AzureOpenAIVectorizerParameters,\n",
    "    SearchIndex\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Data Source (Blob Container containting the pdfs)\n",
    "\n",
    "Although only  PDF files are used here, this can be done at a much larger scale and Azure AI Search supports a range of other file formats including: Microsoft Office (DOCX/DOC, XSLX/XLS, PPTX/PPT, MSG), HTML, XML, ZIP, and plain text files (including JSON).\n",
    "Azure Search support the following sources: [Data Sources Gallery](https://learn.microsoft.com/EN-US/AZURE/search/search-data-sources-gallery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes import SearchIndexerClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndexerDataContainer,\n",
    "    SearchIndexerDataSourceConnection\n",
    ")\n",
    "\n",
    "# Create a data source \n",
    "indexer_client = SearchIndexerClient(endpoint=AI_SEARCH_ENDPOINT, credential=AzureKeyCredential(AI_SEARCH_KEY))\n",
    "container = SearchIndexerDataContainer(name=container_name)\n",
    "data_source_connection = SearchIndexerDataSourceConnection(\n",
    "    name=container_name+\"-connection\",\n",
    "    type=\"azureblob\",\n",
    "    connection_string=BLOB_STORAGE_ACCOUNT_CONNECTION_STRING,\n",
    "    container=container\n",
    ")\n",
    "data_source = indexer_client.create_or_update_data_source_connection(data_source_connection)\n",
    "\n",
    "print(f\"Data source '{data_source.name}' created or updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    "    AzureOpenAIVectorizer,\n",
    "    AzureOpenAIVectorizerParameters,\n",
    "    SearchIndex\n",
    ")\n",
    "\n",
    "AZURE_SEARCH_CREDENTIAL = AzureKeyCredential(AI_SEARCH_KEY)\n",
    "\n",
    "# Create a search index  \n",
    "index_name = container_name+\"-index\"\n",
    "index_client = SearchIndexClient(endpoint=AI_SEARCH_ENDPOINT, credential=AZURE_SEARCH_CREDENTIAL)  \n",
    "fields = [\n",
    "    SearchField(name=\"parent_id\", type=SearchFieldDataType.String),\n",
    "    SearchField(name=\"title\", type=SearchFieldDataType.String),\n",
    "    SearchField(name=\"chunk_id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True, analyzer_name=\"keyword\"),  \n",
    "    SearchField(name=\"chunk\", type=SearchFieldDataType.String, sortable=False, filterable=False, facetable=False),\n",
    "    SearchField(name=\"image_sas_url\", type=SearchFieldDataType.String, sortable=False, filterable=False, facetable=False),\n",
    "    SearchField(name=\"page_number\", type=SearchFieldDataType.String, sortable=False, filterable=False, facetable=False),\n",
    "    SearchField(name=\"text_vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), vector_search_dimensions=1536, vector_search_profile_name=\"myHnswProfile\")\n",
    "    ]  \n",
    "  \n",
    "# Configure the vector search configuration  \n",
    "vector_search = VectorSearch(  \n",
    "    algorithms=[  \n",
    "        HnswAlgorithmConfiguration(name=\"myHnsw\"),\n",
    "    ],  \n",
    "    profiles=[  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"myHnswProfile\",  \n",
    "            algorithm_configuration_name=\"myHnsw\",  \n",
    "            vectorizer_name=\"myOpenAI\",  \n",
    "        )\n",
    "    ],  \n",
    "    vectorizers=[  \n",
    "        AzureOpenAIVectorizer(  \n",
    "            vectorizer_name=\"myOpenAI\",  \n",
    "            kind=\"azureOpenAI\",  \n",
    "            parameters=AzureOpenAIVectorizerParameters(  \n",
    "                resource_url=OPENAI_API_ENDPOINT,  \n",
    "                deployment_name=os.getenv(\"EMBEDDINGS_MODEL_NAME\"),\n",
    "                model_name=\"text-embedding-ada-002\",\n",
    "                api_key=OPENAI_API_KEY\n",
    "            ),\n",
    "        ),  \n",
    "    ], \n",
    ")  \n",
    "  \n",
    "# Create the search index\n",
    "index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search)  \n",
    "result = index_client.create_or_update_index(index)  \n",
    "print(f\"{result.name} created\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Skill Set\n",
    "One option for data pre-processing is to do it as part of the indexing by using a skillset.\n",
    "A Skillset is a set of steps in which AI Services can be used to enrich the documents by extracting information, applying OCR, translating, etc.\n",
    "\n",
    "https://learn.microsoft.com/en-us/azure/search/cognitive-search-working-with-skillsets\n",
    "https://learn.microsoft.com/en-us/azure/search/cognitive-search-predefined-skills\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import ( \n",
    "    SplitSkill,\n",
    "    InputFieldMappingEntry,\n",
    "    OutputFieldMappingEntry,\n",
    "    AzureOpenAIEmbeddingSkill,\n",
    "    EntityRecognitionSkill,\n",
    "    SearchIndexerIndexProjection,\n",
    "    SearchIndexerIndexProjectionSelector,\n",
    "    SearchIndexerIndexProjectionsParameters,\n",
    "    IndexProjectionMode,\n",
    "    SearchIndexerSkillset,\n",
    "    CognitiveServicesAccountKey,\n",
    "    WebApiSkill,\n",
    "    SearchIndexerDataUserAssignedIdentity\n",
    ")\n",
    "\n",
    "# Create a skillset  \n",
    "skillset_name = container_name+\"-skillset\"\n",
    "\n",
    "pdftoimage_skill = WebApiSkill(\n",
    "    description=\"Skill to generate images from pdf\",\n",
    "    uri=GENAI_CUSTOMSKILL_FUNCTION_URL+\"pdftoimage\",\n",
    "    context=\"/document\",\n",
    "    inputs=[\n",
    "        InputFieldMappingEntry(name=\"docUrl\", source=\"/document/metadata_storage_path\"),\n",
    "        InputFieldMappingEntry(name=\"docSAS\", source=\"/document/metadata_storage_sas_token\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        OutputFieldMappingEntry(name=\"image_sas_urls\", target_name=\"pages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "imagetomarkdown_skill = WebApiSkill(\n",
    "    description=\"Skill to generate images from pdf\",\n",
    "    uri=GENAI_CUSTOMSKILL_FUNCTION_URL+\"imagetomarkdown\",\n",
    "    context=\"/document/pages/*\",\n",
    "    inputs=[\n",
    "        InputFieldMappingEntry(name=\"image_sas_url\", source=\"/document/pages/*/sas_url\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        OutputFieldMappingEntry(name=\"markdown\", target_name=\"markdown\"),\n",
    "        OutputFieldMappingEntry(name=\"page_number\", target_name=\"page_number\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "embedding_skill = AzureOpenAIEmbeddingSkill(  \n",
    "    description=\"Skill to generate embeddings via Azure OpenAI\",  \n",
    "    context=\"/document/pages/*\",\n",
    "    resource_url=OPENAI_API_ENDPOINT,\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    deployment_name=os.getenv(\"EMBEDDINGS_MODEL_NAME\"),\n",
    "    model_name=\"text-embedding-ada-002\",\n",
    "    dimensions=1536,\n",
    "    inputs=[  \n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/pages/*/page_number\"),  \n",
    "    ],  \n",
    "    outputs=[  \n",
    "        OutputFieldMappingEntry(name=\"embedding\", target_name=\"text_vector\")  \n",
    "    ],  \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "skills = [pdftoimage_skill, imagetomarkdown_skill, embedding_skill]\n",
    "\n",
    "\n",
    "index_projections = SearchIndexerIndexProjection(  \n",
    "    selectors=[  \n",
    "        SearchIndexerIndexProjectionSelector(  \n",
    "            target_index_name=index_name,  \n",
    "            parent_key_field_name=\"parent_id\",  \n",
    "            source_context=\"/document/pages/*\",  \n",
    "            mappings=[ \n",
    "                InputFieldMappingEntry(name=\"chunk\", source=\"/document/pages/*/markdown\"),\n",
    "                InputFieldMappingEntry(name=\"image_sas_url\", source=\"/document/pages/*/sas_url\"),  \n",
    "                InputFieldMappingEntry(name=\"text_vector\", source=\"/document/pages/*/text_vector\"),\n",
    "                InputFieldMappingEntry(name=\"page_number\", source=\"/document/pages/*/page_number\"),\n",
    "                InputFieldMappingEntry(name=\"title\", source=\"/document/metadata_storage_name\"),  \n",
    "            ],  \n",
    "        ),  \n",
    "    ],  \n",
    "    parameters=SearchIndexerIndexProjectionsParameters(  \n",
    "        projection_mode=IndexProjectionMode.SKIP_INDEXING_PARENT_DOCUMENTS  \n",
    "    ),  \n",
    ") \n",
    "\n",
    "cognitive_services_account = CognitiveServicesAccountKey(key=AZURE_AI_KEY)\n",
    "\n",
    "\n",
    "skillset = SearchIndexerSkillset(  \n",
    "    name=skillset_name,  \n",
    "    description=\"Skillset to chunk documents and generating embeddings\",  \n",
    "    skills=skills,\n",
    "    index_projection=index_projections,\n",
    "    cognitive_services_account=cognitive_services_account\n",
    ")\n",
    "\n",
    "client = SearchIndexerClient(endpoint=AI_SEARCH_ENDPOINT, credential=AZURE_SEARCH_CREDENTIAL)  \n",
    "client.create_or_update_skillset(skillset)  \n",
    "print(f\"{skillset.name} created\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndexer,\n",
    "    FieldMapping\n",
    ")\n",
    "\n",
    "# Create an indexer \n",
    "indexer_name = container_name+\"-indexer\" \n",
    "\n",
    "indexer_parameters = None\n",
    "\n",
    "indexer = SearchIndexer(  \n",
    "    name=indexer_name,  \n",
    "    description=\"Indexer to index documents and generate embeddings\",  \n",
    "    skillset_name=skillset_name,  \n",
    "    target_index_name=index_name,  \n",
    "    data_source_name=data_source.name,\n",
    "    parameters=indexer_parameters\n",
    ")  \n",
    "\n",
    "# Create and run the indexer  \n",
    "indexer_client = SearchIndexerClient(endpoint=AI_SEARCH_ENDPOINT, credential=AZURE_SEARCH_CREDENTIAL) \n",
    "\n",
    "indexer_result = indexer_client.create_or_update_indexer(indexer)\n",
    "\n",
    "\n",
    "print(f' {indexer_name} is created and running. Give the indexer a few minutes before running a query.')  "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
